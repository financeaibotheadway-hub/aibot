from google.cloud import bigquery
from vertexai.preview.generative_models import GenerativeModel
import json
from semantic_map import semantic_map
import pandas as pd
import re
import hashlib
import time
from functools import lru_cache
import os

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ BigQuery (Ñ–Ğ· Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚Ğ°Ğ¼Ğ¸ Ğ¿Ñ–Ğ´ Ğ²Ğ°Ñˆ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚/Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚/Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BQ_PROJECT       = os.getenv("BIGQUERY_PROJECT", "finance-ai-bot-headway")
BQ_DATASET       = os.getenv("BQ_DATASET", "uploads")
BQ_REVENUE_TABLE = os.getenv("BQ_REVENUE_TABLE", "revenue_test_databot")
BQ_COST_TABLE    = os.getenv("BQ_COST_TABLE", "cost_test_databot")

REVENUE_TABLE_REF = f"{BQ_PROJECT}.{BQ_DATASET}.{BQ_REVENUE_TABLE}"
COST_TABLE_REF    = f"{BQ_PROJECT}.{BQ_DATASET}.{BQ_COST_TABLE}"

# Ğ†Ğ½Ñ–Ñ†Ñ–Ğ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ ĞºĞ»Ñ–Ñ”Ğ½Ñ‚Ñ–Ğ²
bq_client = bigquery.Client(project=BQ_PROJECT)
model = GenerativeModel("gemini-2.5-flash")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ĞšĞµÑˆ Ğ´Ğ»Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ–Ğ² Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñ–Ğ² Ñ‚Ğ° ÑÑ…ĞµĞ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
query_cache = {}
cache_ttl = 300  # 5 Ñ…Ğ²Ğ¸Ğ»Ğ¸Ğ½

# ĞºĞµÑˆ ÑÑ…ĞµĞ¼ Ğ¿Ğ¾ ĞºĞ¾Ğ¶Ğ½Ñ–Ğ¹ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–
_schema_cache = {}   # {table_ref: [ {name,type}, ... ]}
_schema_time  = {}   # {table_ref: unix_ts}


def get_cache_key(query: str) -> str:
    return hashlib.md5(query.encode()).hexdigest()


def get_table_schema(table_ref: str, ttl_sec: int = 3600):
    """ĞšĞµÑˆĞ¾Ğ²Ğ°Ğ½Ğ° ÑÑ…ĞµĞ¼Ğ° ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ñ— Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–."""
    now = time.time()
    if (
        table_ref not in _schema_cache
        or table_ref not in _schema_time
        or now - _schema_time[table_ref] > ttl_sec
    ):
        schema = bq_client.get_table(table_ref).schema
        _schema_cache[table_ref] = [{"name": f.name, "type": f.field_type} for f in schema]
        _schema_time[table_ref] = now
    return _schema_cache[table_ref]


def get_all_schemas():
    """ĞŸĞ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” Ğ¾Ğ±Ğ¸Ğ´Ğ²Ñ– ÑÑ…ĞµĞ¼Ğ¸ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°."""
    rev_schema = get_table_schema(REVENUE_TABLE_REF)
    try:
        cost_schema = get_table_schema(COST_TABLE_REF)
    except Exception:
        # ÑĞºÑ‰Ğ¾ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– Ğ²Ğ¸Ñ‚Ñ€Ğ°Ñ‚ Ğ¿Ğ¾ĞºĞ¸ Ğ½ĞµĞ¼Ğ°Ñ” â€” Ğ¿Ñ€Ğ°Ñ†ÑÑ”Ğ¼Ğ¾ Ğ· Ğ¾Ğ´Ğ½Ñ–Ñ”Ñ
        cost_schema = []
    return rev_schema, cost_schema


# ĞŸĞ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½ÑŒĞ¾ Ñ–Ğ½Ñ–Ñ†Ñ–Ğ°Ğ»Ñ–Ğ·ÑƒÑ”Ğ¼Ğ¾ (Ñ‰Ğ¾Ğ± Ğ±ÑƒĞ»Ğ¾ Ñ‰Ğ¾ Ğ¿Ñ–Ğ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑ‚Ğ¸ Ñƒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚)
schema_revenue, schema_cost = get_all_schemas()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ĞšĞµÑˆĞ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ²Ğ¸ĞºĞ¾Ğ½ÑƒĞ²Ğ°Ñ‡ SQL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def execute_cached_query(sql_query):
    cache_key = get_cache_key(sql_query)
    now = time.time()

    if cache_key in query_cache:
        cached_df, ts = query_cache[cache_key]
        if now - ts < cache_ttl:
            return cached_df
        else:
            del query_cache[cache_key]

    df = bq_client.query(sql_query).result().to_dataframe()
    query_cache[cache_key] = (df.copy(), now)

    # Ğ¾Ğ±Ğ¼ĞµĞ¶ÑƒÑ”Ğ¼Ğ¾ Ñ€Ğ¾Ğ·Ğ¼Ñ–Ñ€ ĞºĞµÑˆÑƒ
    if len(query_cache) > 20:
        oldest_key = min(query_cache, key=lambda k: query_cache[k][1])
        del query_cache[oldest_key]
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) Ğ’Ğ°Ğ»Ñ–Ğ´Ğ°Ñ‚Ğ¾Ñ€ SQL (Ğ»ĞµĞ³ĞºÑ– Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def validate_sql_syntax(sql_query):
    errors = []

    window_pattern = r'(?:ROW_NUMBER|RANK|DENSE_RANK|LAG|LEAD)\s*\(\s*\)\s+OVER\s*\([^)]*ORDER\s+BY\s+([^)]+)\)'
    window_matches = re.findall(window_pattern, sql_query, re.IGNORECASE)
    for order_expr in window_matches:
        if 'GROUP BY' in sql_query.upper() and not any(
            field in sql_query.split('GROUP BY')[1] for field in order_expr.split(',')
        ):
            errors.append(f"Window ORDER BY Ğ¼Ñ–ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğµ '{order_expr.strip()}', ÑĞºĞµ Ğ½Ğµ Ğ·Ğ³Ñ€ÑƒĞ¿Ğ¾Ğ²Ğ°Ğ½Ğµ")

    if re.search(r'WHERE\s+\w+\s+IN\s*\(\s*SELECT.*WHERE.*\w+\.\w+\s*=\s*\w+\.\w+', sql_query,
                 re.IGNORECASE | re.DOTALL):
        errors.append("Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ñ– ĞºĞ¾Ñ€ĞµĞ»ÑŒĞ¾Ğ²Ğ°Ğ½Ñ– Ğ¿Ñ–Ğ´Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ¸, ÑĞºÑ– Ğ½Ğµ Ğ¿Ñ–Ğ´Ñ‚Ñ€Ğ¸Ğ¼ÑƒÑÑ‚ÑŒÑÑ BigQuery")

    if 'STRFTIME' in sql_query.upper():
        errors.append("STRFTIME Ğ½Ğµ Ğ¿Ñ–Ğ´Ñ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ñ‚ÑŒÑÑ Ğ² BigQuery. Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹Ñ‚Ğµ FORMAT_DATE")

    return errors

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) AI-Ğ¼Ğ°Ñ‚Ñ‡Ğ¸Ğ½Ğ³ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸ĞºĞ¸ (Ğ·Ğ°Ğ»Ğ¸ÑˆĞ¸Ğ² ÑĞº Ğ±ÑƒĞ»Ğ¾)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@lru_cache(maxsize=100)
def find_matches_with_ai_cached(instruction, semantic_map_str):
    smap = json.loads(semantic_map_str)

    context = {}
    for full_key, phrases in smap.items():
        field, value = full_key.split(":")
        context.setdefault(field, {})
        synonyms = []
        for p in phrases:
            synonyms.append(p.get("text", "") if isinstance(p, dict) else str(p))
        context[field][value] = synonyms

    prompt = f"""
Ğ—Ğ½Ğ°Ğ¹Ğ´Ğ¸ ÑĞºÑ– Ğ¿Ğ¾Ğ»Ñ Ğ·Ğ³Ğ°Ğ´ÑƒÑ” ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡, Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑÑ‡Ğ¸ ÑĞ¸Ğ½Ğ¾Ğ½Ñ–Ğ¼Ğ¸:

Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ– Ğ¿Ğ¾Ğ»Ñ Ñ‚Ğ° ÑĞ¸Ğ½Ğ¾Ğ½Ñ–Ğ¼Ğ¸:
{json.dumps(context, ensure_ascii=False, indent=2)}

Ğ¢ĞµĞºÑÑ‚ ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ğ°: "{instruction}"

ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
- Ğ¯ĞºÑ‰Ğ¾ "Ñ„Ñ–" + "Ñ€ĞµÑ„Ğ°Ğ½Ğ´" â†’ event_type=refund_fee
- Ğ¯ĞºÑ‰Ğ¾ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ "Ñ€ĞµÑ„Ğ°Ğ½Ğ´" â†’ event_type=refund
- Ğ¯ĞºÑ‰Ğ¾ "Ñ„Ñ–" + "Ñ‡Ğ°Ñ€Ğ´Ğ¶Ğ±ĞµĞº" â†’ event_type=chargeback_fee
- Ğ¯ĞºÑ‰Ğ¾ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ "Ñ‡Ğ°Ñ€Ğ´Ğ¶Ğ±ĞµĞº" â†’ event_type=chargeback
"""
    try:
        response = model.generate_content(prompt, generation_config={"temperature": 0})
        result = response.text.strip()
        if result == "NONE":
            return []
        matches = []
        for pair in result.split(','):
            if ':' in pair:
                field, value = pair.strip().split(':', 1)
                matches.append((field, value))
        return matches
    except:
        return []


def find_matches_with_ai(instruction, smap):
    return find_matches_with_ai_cached(instruction, json.dumps(smap, sort_keys=True))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6) Ğ Ğ¾Ğ·Ğ´Ñ–Ğ»ĞµĞ½Ğ½Ñ ÑĞºĞ»Ğ°Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ Ğ½Ğ° Ğ¾ĞºÑ€ĞµĞ¼Ñ– Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ¸ (Ğ·Ğ°Ğ»Ğ¸ÑˆĞ¸Ğ² ÑĞº Ğ±ÑƒĞ»Ğ¾)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def split_into_separate_queries(message: str) -> list:
    split_prompt = f"""
Ğ Ğ¾Ğ·Ğ´Ñ–Ğ»Ğ¸ Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ğ° Ğ½Ğ° Ğ¾ĞºÑ€ĞµĞ¼Ñ– Ğ½ĞµĞ·Ğ°Ğ»ĞµĞ¶Ğ½Ñ– Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ¸. ĞšĞ¾Ğ¶Ğ½Ğµ Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ Ğ°Ğ±Ğ¾ Ğ·Ğ°Ğ²Ğ´Ğ°Ğ½Ğ½Ñ Ğ¼Ğ°Ñ” Ğ±ÑƒÑ‚Ğ¸ Ğ¾ĞºÑ€ĞµĞ¼Ğ¸Ğ¼ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ¾Ğ¼.

ĞŸĞ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ: "{message}"

Ğ—Ğ½Ğ°Ğ¹Ğ´Ğ¸ Ğ²ÑÑ– Ğ¾ĞºÑ€ĞµĞ¼Ñ– Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ/Ğ·Ğ°Ğ²Ğ´Ğ°Ğ½Ğ½Ñ Ñ‚Ğ° Ğ¿ĞµÑ€ĞµĞ»Ñ–Ñ‡Ğ¸ Ñ—Ñ… Ğ² Ñ‚Ğ°ĞºĞ¾Ğ¼Ñƒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ–:
Ğ—ĞĞŸĞ˜Ğ¢_1: [Ğ¿ĞµÑ€ÑˆĞ¸Ğ¹ Ğ·Ğ°Ğ¿Ğ¸Ñ‚]
Ğ—ĞĞŸĞ˜Ğ¢_2: [Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¹ Ğ·Ğ°Ğ¿Ğ¸Ñ‚]
Ğ—ĞĞŸĞ˜Ğ¢_3: [Ñ‚Ñ€ĞµÑ‚Ñ–Ğ¹ Ğ·Ğ°Ğ¿Ğ¸Ñ‚]
"""
    try:
        response = model.generate_content(split_prompt, generation_config={"temperature": 0})
        result = response.text.strip()
        queries = []
        for line in result.split('\n'):
            line = line.strip()
            if line.startswith('Ğ—ĞĞŸĞ˜Ğ¢_'):
                parts = line.split(':', 1)
                if len(parts) == 2 and parts[1].strip():
                    queries.append(parts[1].strip())
        return queries if queries else [message]
    except Exception:
        return [message]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7) Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ñ–Ñ Ñ‚Ğ° Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ½Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñƒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def execute_single_query(instruction: str, smap: dict) -> str:
    try:
        instruction_part = instruction.strip()
        if not instruction_part:
            return "ĞŸĞ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ñ”. ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ–Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ñ–Ñ."

        matched_conditions = find_matches_with_ai(instruction_part, smap)
        for field, value in matched_conditions:
            instruction_part += f" ({field} = '{value}')"

        # ĞĞ½Ğ¾Ğ²Ğ»ÑÑ”Ğ¼Ğ¾ ÑÑ…ĞµĞ¼Ğ¸ Ğ¿ĞµÑ€ĞµĞ´ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ñ–Ñ”Ñ (Ñ€Ğ°Ğ¿Ñ‚Ğ¾Ğ¼ Ğ¾Ğ½Ğ¾Ğ²Ğ¸Ğ»Ğ¸ÑÑŒ)
        rev_schema, cost_schema = get_all_schemas()

        # â”€â”€â”€â”€â”€ ĞŸĞ ĞĞœĞŸĞ¢: Ñ‚ĞµĞ¿ĞµÑ€ Ñ–Ğ· Ğ´Ğ²Ğ¾Ğ¼Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†ÑĞ¼Ğ¸ â”€â”€â”€â”€â”€
        sql_prompt = f"""
Ğ’ Ğ½Ğ°Ñ Ñ” Ğ”Ğ’Ğ† Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– Ğ² BigQuery:

1) **REVENUE**: `{REVENUE_TABLE_REF}`
   Ğ¡Ñ…ĞµĞ¼Ğ°:
{json.dumps(rev_schema, indent=2)}

2) **COST**: `{COST_TABLE_REF}`
   Ğ¡Ñ…ĞµĞ¼Ğ°:
{json.dumps(cost_schema, indent=2)}

Ğ—Ğ³ĞµĞ½ĞµÑ€ÑƒĞ¹ Ğ•ĞšĞ¡ĞŸĞ•Ğ Ğ¢ĞĞ˜Ğ™ BigQuery SQL Ğ´Ğ»Ñ Ğ·Ğ°Ğ²Ğ´Ğ°Ğ½Ğ½Ñ: {instruction_part}

ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
- Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ Ğ¢Ğ†Ğ›Ğ¬ĞšĞ˜ BigQuery SQL.
- ĞĞµ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ STRFTIME; Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ–Ğ² Ğ´Ğ°Ñ‚: FORMAT_DATE('%Y-%m', DATE(...)).
- ĞĞµ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ ĞºĞ¾Ñ€ĞµĞ»ÑŒĞ¾Ğ²Ğ°Ğ½Ñ– Ğ¿Ñ–Ğ´Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ¸.
- Ğ¯ĞºÑ‰Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ñ– window-Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ— â€” Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ ĞºĞ¾Ñ€ĞµĞºÑ‚Ğ½Ğ¾ Ğ· GROUP BY.
- Ğ¯ĞºÑ‰Ğ¾ Ğ·Ğ°Ğ¿Ğ¸Ñ‚ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ Ğ¿Ñ€Ğ¾ Ğ´Ğ¾Ñ…Ñ–Ğ´/Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ñ– â€” Ğ±ĞµÑ€Ğ¸ Ğ´Ğ°Ğ½Ñ– Ğ· Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– REVENUE.
- Ğ¯ĞºÑ‰Ğ¾ Ğ·Ğ°Ğ¿Ğ¸Ñ‚ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ Ğ¿Ñ€Ğ¾ Ğ²Ğ¸Ñ‚Ñ€Ğ°Ñ‚Ğ¸/ÑĞ¿ĞµĞ½Ğ´/ĞºĞ¾ÑÑ‚ â€” Ğ±ĞµÑ€Ğ¸ Ğ· Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– COST.
- Ğ¯ĞºÑ‰Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ñ– **ROAS** Ğ°Ğ±Ğ¾ **Ğ¿Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğº**, Ğ°Ğ³Ñ€ĞµĞ³ÑƒĞ¹ REVENUE Ñ– COST ĞĞšĞ Ğ•ĞœĞ,
  Ğ¿Ğ¾Ñ‚Ñ–Ğ¼ **JOIN** Ğ·Ğ° ÑĞ¿Ñ–Ğ»ÑŒĞ½Ğ¸Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸ (ÑĞ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºÑƒ Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ date/Ğ´Ğ°Ñ‚Ğ°;
  ÑĞºÑ‰Ğ¾ Ñ” ÑĞ¿Ñ–Ğ»ÑŒĞ½Ñ– Ğ¿Ğ¾Ğ»Ñ `sourceMedium/source`, `campaign`, `app_name` â€” Ğ´Ğ¾Ğ´Ğ°Ğ¹ Ñ—Ñ… Ñƒ ĞºĞ»ÑÑ‡Ñ– Ğ´Ğ¶Ğ¾Ğ¹Ğ½Ñƒ).
- **ROAS = revenue_value / cost_value**.
- **ĞŸÑ€Ğ¾Ñ„Ñ–Ñ‚/Ğ¿Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğº = revenue_value - cost_value**.
- Ğ£ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– COST Ğ²Ğ¸Ğ±Ğ¸Ñ€Ğ°Ğ¹ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğµ Ğ¿Ğ¾Ğ»Ğµ Ğ²Ğ¸Ñ‚Ñ€Ğ°Ñ‚ (Ğ¿ĞµÑ€ĞµĞ²Ğ°Ğ³Ğ° Ğ½Ğ°Ğ·Ğ²Ğ°Ğ¼: cost, spend, ad_cost, amount, value, usd).
- Ğ£ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– REVENUE Ğ´Ğ»Ñ "net revenue"/"Ğ½ĞµÑ‚ Ñ€ĞµĞ²ĞµĞ½ÑŒÑ" â€” ÑÑƒĞ¼ÑƒĞ¹ **gross_usd** (ĞĞ• Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€ÑƒĞ¹ event_type='sale'; Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ ÑƒÑÑ– event_type).
- ĞŸĞ¾Ğ»Ğµ **period** (12M/1M/6M) â€” Ñ†Ğµ **Ñ‚Ğ¸Ğ¿ Ğ¿Ñ–Ğ´Ğ¿Ğ¸ÑĞºĞ¸**, Ğ½Ğµ Ñ‡Ğ°ÑĞ¾Ğ²Ğ¸Ğ¹ Ğ¿ĞµÑ€Ñ–Ğ¾Ğ´. Ğ™Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ° Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ²Ğ°Ñ‚Ğ¸ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ Ğ² GROUP BY Ğ´Ğ»Ñ Ñ€Ğ¾Ğ·Ñ€Ñ–Ğ·Ñ–Ğ² Ñ‚Ğ¸Ğ¿Ñ–Ğ² Ğ¿Ñ–Ğ´Ğ¿Ğ¸ÑĞºĞ¸. ĞĞµ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ period Ñƒ LAG/LEAD/ORDER BY ÑĞº Ñ‡Ğ°Ñ.
- ĞŸĞ¾Ğ²ĞµÑ€Ñ‚Ğ°Ğ¹ Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ Ñ„Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ SQL-Ğ·Ğ°Ğ¿Ğ¸Ñ‚ Ğ±ĞµĞ· Ğ¿Ğ¾ÑÑĞ½ĞµĞ½ÑŒ.
"""
        response = model.generate_content(sql_prompt, generation_config={"temperature": 0})
        sql_query = response.text.strip().replace("```sql", "").replace("```", "").strip()
        if sql_query.lower().startswith("sql"):
            sql_query = sql_query[3:].strip()

        errs = validate_sql_syntax(sql_query)
        if errs:
            return "âŒ **ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ² Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñ–:**\n" + "\n".join(f"â€¢ {e}" for e in errs)

        try:
            df = execute_cached_query(sql_query)
        except Exception as bq_error:
            msg = "âŒ **ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ½Ñ– Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñƒ Ğ´Ğ¾ Ğ±Ğ°Ğ·Ğ¸ Ğ´Ğ°Ğ½Ğ¸Ñ….**\n"
            if "Window ORDER BY" in str(bq_error):
                msg += "ğŸ’¡ ĞŸĞ¾Ñ€Ğ°Ğ´Ğ°: Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ· window-Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ”Ñ. Ğ¡Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ–ÑˆĞµ Ğ·Ğ³Ğ¾Ñ€Ñ‚Ğ°Ğ½Ğ½Ñ."
            elif "Correlated subqueries" in str(bq_error):
                msg += "ğŸ’¡ ĞŸĞ¾Ñ€Ğ°Ğ´Ğ°: Ğ¿Ñ€Ğ¸Ğ±ĞµÑ€Ñ–Ñ‚ÑŒ ĞºĞ¾Ñ€ĞµĞ»ÑŒĞ¾Ğ²Ğ°Ğ½Ñ– Ğ¿Ñ–Ğ´Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ¸."
            elif "invalidQuery" in str(bq_error):
                msg += "ğŸ’¡ ĞŸĞ¾Ñ€Ğ°Ğ´Ğ°: ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ‡Ğ½Ğ° Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ² SQL."
            return msg

        if df.empty:
            return "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ– Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ñ–Ğ¹."

        analysis_prompt = f"""
Ğ—Ñ€Ğ¾Ğ±Ğ¸ Ñ‚Ğµ, Ñ‰Ğ¾ Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡ Ğ² Ñ–Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ñ–Ñ—.
Ğ†Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ñ–Ñ: "{instruction_part}"

CSV Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ SQL:
{df.to_csv(index=False)}

Ğ’Ğ¸Ğ¼Ğ¾Ğ³Ğ¸:
- ĞĞµ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ğ¹ SQL Ñƒ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ñ–.
- ĞĞµ Ğ²Ğ¸Ğ³Ğ°Ğ´ÑƒĞ¹ Ğ´Ğ°Ğ½Ğ¸Ñ… Ğ°Ğ±Ğ¾ Ğ´Ğ°Ñ‚ â€” Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ Ñ‚Ğµ, Ñ‰Ğ¾ Ğ² Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–.
- Ğ¯ĞºÑ‰Ğ¾ Ñ Ğ¿Ñ€Ğ¾ÑĞ¸Ğ² Ğ°Ğ½Ğ°Ğ»Ñ–Ñ‚Ğ¸ĞºÑƒ/Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ½Ñ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½ â€” Ğ½Ğµ Ğ±Ñ–Ğ»ÑŒÑˆĞµ 3â€“4 Ñ€ĞµÑ‡ĞµĞ½ÑŒ.
- period (12M/1M/6M) â€” Ñ†Ğµ Ñ‚Ğ¸Ğ¿Ğ¸ Ğ¿Ñ–Ğ´Ğ¿Ğ¸ÑĞ¾Ğº, Ğ½Ğµ Ñ‡Ğ°Ñ.
- Ğ¯ĞºÑ‰Ğ¾ Ñ” Ñ€Ğ¾Ğ·Ñ€Ñ–Ğ·Ğ¸, Ğ¼Ğ¾Ğ¶Ğ½Ğ° Ğ·Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚Ğ¸: "Ğ¿Ñ–Ğ´Ğ¿Ğ¸ÑĞºĞ° 12M Ğ¿Ñ€Ğ°Ñ†ÑÑ” ĞºÑ€Ğ°Ñ‰Ğµ Ğ½Ñ–Ğ¶ 1M".
"""
        analysis_response = model.generate_content(analysis_prompt, generation_config={"temperature": 0})
        return analysis_response.text.strip()

    except Exception as e:
        return f"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ–Ğ´ Ñ‡Ğ°Ñ Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ¸:\n{str(e)}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8) ĞĞ±Ñ€Ğ¾Ğ±ĞºĞ° ÑĞºĞ»Ğ°Ğ´Ğ½Ğ¸Ñ… Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½ÑŒ Ñ– Ñ„Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ²Ğ¸ÑĞ½Ğ¾Ğ²Ğ¾Ğº (Ğ±ĞµĞ· Ğ·Ğ¼Ñ–Ğ½ Ğ¿Ğ¾ ÑÑƒÑ‚Ñ–)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_slack_message(message: str, smap: dict) -> str:
    try:
        if not message.strip():
            return "ĞŸĞ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ Ğ¿Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ñ”. ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ–Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ñ–Ñ."
        queries = split_into_separate_queries(message)
        if len(queries) == 1:
            return execute_single_query(queries[0], smap)

        results = []
        for i, q in enumerate(queries, 1):
            print(f"Ğ’Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ½Ñ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñƒ {i}/{len(queries)}: {q}")
            results.append((i, q, execute_single_query(q, smap)))

        final = f"ğŸ“ **Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(queries)} Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñ–Ğ². Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ°Ñ Ğ½Ğ° ĞºĞ¾Ğ¶ĞµĞ½:**\n\n"
        for i, q, r in results:
            final += f"**ğŸ” Ğ—Ğ°Ğ¿Ğ¸Ñ‚ {i}:** *{q}*\n\n{r}\n\n" + "="*60 + "\n\n"
        return final.rstrip("\n=").rstrip()
    except Exception as e:
        return f"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ–Ğ´ Ñ‡Ğ°Ñ Ğ¾Ğ±Ñ€Ğ¾Ğ±ĞºĞ¸ Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ:\n{str(e)}"


def generate_final_conclusion(results: list, original_message: str) -> str:
    try:
        conclusions = []
        for i, q, r in results:
            if "Ğ’Ğ¸ÑĞ½Ğ¾Ğ²Ğ¾Ğº:" in r:
                conclusions.append(f"Ğ—Ğ°Ğ¿Ğ¸Ñ‚ {i}: {r.split('Ğ’Ğ¸ÑĞ½Ğ¾Ğ²Ğ¾Ğº:')[-1].strip()}")
        if not conclusions:
            return ""
        summary_prompt = f"""
ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ–Ğ² Ğ²ÑÑ–Ñ… Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñ–Ğ² Ğ´Ğ°Ğ¹ Ğ¾Ğ´Ğ¸Ğ½ Ğ·Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ²Ğ¸ÑĞ½Ğ¾Ğ²Ğ¾Ğº.

ĞÑ€Ğ¸Ğ³Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğµ Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ: "{original_message}"
Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸:
{chr(10).join(conclusions)}

Ğ¡Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ¹ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¿Ñ–Ğ´ÑÑƒĞ¼Ğ¾Ğº (2â€“4 Ñ€ĞµÑ‡ĞµĞ½Ğ½Ñ).
"""
        response = model.generate_content(summary_prompt, generation_config={"temperature": 0})
        return f"ğŸ“‹ **Ğ—ĞĞ“ĞĞ›Ğ¬ĞĞ˜Ğ™ Ğ’Ğ˜Ğ¡ĞĞĞ’ĞĞš:**\n{response.text.strip()}"
    except Exception:
        return f"ğŸ“‹ **Ğ—ĞĞ“ĞĞ›Ğ¬ĞĞ˜Ğ™ Ğ’Ğ˜Ğ¡ĞĞĞ’ĞĞš:**\nĞ’ÑÑ– Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ğ¸ Ğ¾Ğ±Ñ€Ğ¾Ğ±Ğ»ĞµĞ½Ğ¾ ÑƒÑĞ¿Ñ–ÑˆĞ½Ğ¾."

# Ğ£Ñ‚Ğ¸Ğ»Ñ–Ñ‚Ğ¸ ĞºĞµÑˆÑƒ
def clear_cache():
    global query_cache, _schema_cache
    query_cache.clear()
    _schema_cache.clear()
    _schema_time.clear()
    find_matches_with_ai_cached.cache_clear()

def get_cache_stats():
    return {
        "query_cache_size": len(query_cache),
        "ai_cache_info": find_matches_with_ai_cached.cache_info()
    }
